\documentclass[12pt]{scrartcl}
\usepackage{notes_2023}

\begin{document}
	%\title{}
	%\maketitle

	\begin{definition}[prodotto scalare standard in $\RR^n$]
		Si definisce \textbf{prodotto scalare} (standard)
		la forma bilineare simmetrica definita
		positiva di $\RR^n$ la cui matrice associata nella
		base canonica di $\RR^n$ è l'identità. In particolare
		vale che:
		\[ v \cdot w = \sum_{i=1}^n v_i w_i. \]
	\end{definition}
	
	\begin{remark}
		Dall'Algebra lineare, ogni iperpiano $P$ di $\RR^{n}$ è
		rappresentabile tramite traslazione di una giacitura che è ortogonale rispetto a una retta,
		ossia esistono sempre $c \in \RR$ e $v \in \RR^{n}$ tale per cui:
		\[ x \in P \iff x \cdot v = c. \]
	\end{remark}
	
	\begin{definition}[derivata direzionale]
		Dati $x_0 \in \RR^n$, $f : \RR^n \to \RR$, e
		$v \in \RR^n$, definisco la \textbf{derivata direzionale}
		come:
		\[ \frac{\partial f}{\partial v}(x_0) = \lim_{\eps \to 0} \frac{f(x + \eps v) - f(x)}{\eps}. \]
	\end{definition}
	
	\begin{remark}
		Si osserva che vale la seguente identità:
		\[ \frac{\partial f}{\partial \lambda v} = \lambda \frac{\partial f}{\partial v}, \]
		e che se $v = 0$, allora la derivata direzionale vale
		sempre $0$.
	\end{remark}
	
	\begin{remark}
		Non vale la linearità sui vettori della derivata
		direzionale, ossia, in generale, vale che:
		\[ \frac{\partial f}{\partial (v + w)} \neq \frac{\partial f}{\partial v} + \frac{\partial f}{\partial w}. \]
		Se infatti si definisce $f$ tale per cui:
		\[ f(x, y) = \begin{cases}
			\frac{x^2 y}{x^2 + y^2} & (x, y) \neq 0,
			\\ 0 & (x, y) = 0,
		\end{cases} \]
		allora $\frac{\partial f}{\partial e_1}(0) =
		\frac{\partial f}{\partial e_2}(0) = 0$, ma
		$\frac{\partial f}{\partial (1,1)}(0) = \frac{1}{2}$.
	\end{remark}
	
	\begin{remark}
		Trovando un'analogia con $\RR$, vale la seguente identità:
		\[ f(x_0 + \eps v) = f(x_0) + \eps \frac{\partial f}{\partial v}(x_0) + o(\abs{\eps v}). \]
		In particolare si osserva che l'$o$-piccolo dipende dal
		vettore direzionale scelto.
	\end{remark}
	
	\begin{definition}[derivata parziale]
		Si definisce \textbf{derivata parziale} rispetto a
		$x_i$, la derivata direzionale rispetto al vettore
		$e_i$, e si indica con:
		\[ \frac{\partial f}{\partial x_i} := \frac{\partial f}{\partial e_i} \]
	\end{definition}
	
	\begin{remark}
		Se $\frac{\partial f}{\partial v}$ fosse lineare su $v$,
		allora si potrebbe riscrivere la derivata direzionale come:
		\[ \frac{\partial f}{\partial v} = \nabla \! f \, v, \quad
			\nabla f = \left(\frac{\partial f}{\partial x_1} \cdots \frac{\partial f}{\partial x_n}\right), \]
		dove $\nabla f$ è così composto perché in ogni colonna
		raccoglie la sua valutazione nella base canonica, ossia
		le derivate parziali.
	\end{remark}
	
	\begin{definition}[gradiente di $f$]
		Si definisce \textbf{gradiente} di una funzione $f : \RR^n \to \RR$ il vettore:
		\[ \nabla f = \left(\frac{\partial f}{\partial x_1} \cdots \frac{\partial f}{\partial x_n}\right). \]
	\end{definition}
	
	\begin{definition}[differenziabilità]
		Si dice che $f$ è \textbf{differenziabile} se esiste
		$\omega \in \RR^n$ tale per cui:
		\[ f(x) = f(x_0) + (x-x_0) \cdot \omega + o(\abs{x-x_0}). \]
		In tal caso si dice che $\omega$ è il suo \textbf{differenziale} e si indica con $Df(x_0)$.
	\end{definition}
\end{document}
